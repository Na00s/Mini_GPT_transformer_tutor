# Transformer_tutor
This is a repository that investigates different ways of coding a language model, and especially implements gpt-like LLMs by training transformer decoders on Machine Learning Lecture slides.
